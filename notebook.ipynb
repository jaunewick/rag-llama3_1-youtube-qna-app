{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# MODEL = \"gpt-3.5-turbo\"\n",
    "MODEL = \"llama3.1\"\n",
    "\n",
    "# Sam Altman: OpenAI CEO on GPT-4, ChatGPT, and the Future of AI\n",
    "YOUTUBE_VIDEO_URL = \"https://www.youtube.com/watch?v=L_Guz73e6fw\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up llm/slm model with its corresponding embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "if MODEL.startswith(\"gpt\"):\n",
    "    model = ChatOpenAI(api_key=OPENAI_API_KEY,model=MODEL)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "else:\n",
    "    model = Ollama(model=MODEL)\n",
    "    embeddings = OllamaEmbeddings(model=MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple model test to verify if it's working.\n",
    "\n",
    "Extracting the response by chaining the model with an output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's one:\\n\\nWhat do you call a fake noodle?\\n\\nAn impasta.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "chain = model | parser\n",
    "chain.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: \n",
      "Answer the question based on the context below.\n",
      "If you can't answer the question, reply \"I don't know\"\n",
      "\n",
      "Context: Here is some context\n",
      "\n",
      "Question: Here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below.\n",
    "If you can't answer the question, reply \"I don't know\"\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\", question=\"Here is a question\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple test to see if the model & prompt template was done correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Daniel.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "chain.invoke({\n",
    "    \"context\": \"The name I was given was Daniel\",\n",
    "    \"question\": \"What's my name ?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate translation prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "translation_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate {answer} to {language}\"\n",
    ")\n",
    "\n",
    "translation_chain = (\n",
    "    {\"answer\": chain, \"language\": itemgetter(\"language\")} | translation_prompt | model | parser\n",
    ")\n",
    "\n",
    "translation_chain.invoke(\n",
    "    {\n",
    "        \"context\": \"Daniel want to order calamari for lunch. He does'nt like anything else.\",\n",
    "        \"question\": \"How many dishes did Daniel ordered?\",\n",
    "        \"language\": \"fran√ßais\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribing YouTube Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcribing a ~2 and half hour video, the following code might take a few minutes.\n",
    "\n",
    "Note : Using pytubefix instead of pytube. The developers of this library are trying to fix the HTTP 400 response error as of August 21st 2024..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from pytubefix import YouTube\n",
    "import whisper\n",
    "\n",
    "\n",
    "if not os.path.exists(\"ytb_transcript.txt\"):\n",
    "    youtube = YouTube(YOUTUBE_VIDEO_URL)\n",
    "    audio = youtube.streams.filter(only_audio=True).first()\n",
    "\n",
    "    # \"base\" model used for ok accuracy and fast transcribing\n",
    "    whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        file = audio.download(output_path=tmpdir)\n",
    "        transcription = whisper_model.transcribe(file, fp16=False)[\"text\"].strip()\n",
    "\n",
    "        with open(\"ytb_transcript.txt\", \"w\") as file:\n",
    "            file.write(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the transcript into smaller documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"ytb_transcript.txt\")\n",
    "txt_documents = loader.load()\n",
    "txt_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "documents = txt_splitter.split_documents(txt_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the documents into a vector store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielgiaoo/Developer/GitHub/rag-youtube-qna-app/.venv/lib/python3.12/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve & passing a setup map through the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "setup = RunnableParallel(context=retriever, question=RunnablePassthrough())\n",
    "chain = setup | prompt | model | parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try it out on our newly created chain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It seems like the conversation doesn\\'t explicitly state what the future of AI will be, but rather hints at its potential and the opinions of some experts in the field.\\n\\nThe quote from Alan Turing (1951) mentions that \"it seems probable that once the machine thinking method has started, it would not take long to outstrip our feeble powers. At some stage, therefore, we should have to expect the machines to take control.\"\\n\\nHowever, the rest of the conversation doesn\\'t provide a clear answer on what this future will hold.\\n\\nI don\\'t know'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is the future of AI ?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
